# ğŸ§­ Runbook: [TÃ­tulo descritivo do incidente ou rotina]
> **Objetivo:** Explique em uma linha o que este runbook resolve ou executa.  
> Exemplo: â€œRestabelecer o serviÃ§o de checkout quando a API retorna erro 503.â€

---

## ğŸ“ Contexto
Descreva o cenÃ¡rio em que este runbook deve ser usado:
- ServiÃ§o ou sistema afetado.
- CondiÃ§Ãµes tÃ­picas do incidente.
- RelaÃ§Ã£o com SLOs ou dependÃªncias crÃ­ticas.

> Exemplo:  
> Este runbook trata falhas intermitentes no `checkout-service` causadas por saturaÃ§Ã£o de conexÃµes com o banco de dados.

---

## ğŸ” Sintomas
Liste os sinais observÃ¡veis que indicam a necessidade deste runbook:
- Alertas especÃ­ficos (ex: â€œHTTP 5xx > 5%â€)
- Logs de erro.
- MÃ©tricas anormais.

**Exemplo:**
- `SQLTimeoutException` no log do serviÃ§o.
- MÃ©trica `http_request_duration_seconds > 2s`.
- LatÃªncia elevada em dashboard Grafana.

---

## ğŸ’¥ Impacto
Descreva o impacto operacional e de negÃ³cio:
- ServiÃ§os degradados.
- SLOs violados.
- PossÃ­vel perda de receita ou experiÃªncia do usuÃ¡rio.

**Exemplo:**  
Indisponibilidade parcial do fluxo de pagamentos, afetando checkout e histÃ³rico de pedidos.

---

## ğŸ§  Causa ProvÃ¡vel
Liste hipÃ³teses conhecidas ou causas mais comuns observadas em incidentes anteriores.

**Exemplo:**
- ExaustÃ£o do pool de conexÃµes JDBC.  
- Falha no serviÃ§o de banco de dados.  
- Aumento repentino de trÃ¡fego.

---

## ğŸ§ª DiagnÃ³stico (Passo a passo)
Passos para confirmar a causa do problema.  
Cada passo deve ser reproduzÃ­vel por qualquer operador.

1. **Verificar status do pod:**
   ```bash
   kubectl get pods -n payments | grep checkout
   ```
2. **Consultar logs recentes:**
   ```bash
   kubectl logs deployment/checkout-service --tail=100
   ```
3. **Validar conexÃ£o com o banco:**
   ```bash
   kubectl exec -it pod/checkout-xyz -- nc -zv db-service 5432
   ```
4. **Checar mÃ©tricas:**
   - Prometheus: `rate(http_requests_total{status="5xx"}[5m])`
   - Grafana Dashboard: *Checkout Performance*

> ğŸ’¡ *Se falha de rede for detectada â†’ seguir para Runbook â€œnetwork-connectivity-issue.mdâ€.*

---

## ğŸ› ï¸ CorreÃ§Ã£o (Passo a passo)
AÃ§Ãµes para resolver ou mitigar o problema.  
Inclua comandos, scripts ou automaÃ§Ãµes possÃ­veis.

1. Reiniciar o serviÃ§o:
   ```bash
   kubectl rollout restart deployment checkout-service
   ```
2. Confirmar estabilizaÃ§Ã£o:
   ```bash
   kubectl get pods -n payments | grep checkout
   ```
3. Validar que o novo pod estÃ¡ pronto:
   ```bash
   kubectl describe pod checkout-service | grep "State"
   ```
4. Verificar logs:
   ```bash
   kubectl logs deployment/checkout-service --tail=20
   ```
5. Validar no Grafana se latÃªncia < 300ms e erro 5xx = 0.

> âš ï¸ **AtenÃ§Ã£o:** nunca reiniciar mais de uma rÃ©plica simultaneamente em horÃ¡rio comercial.

---

## ğŸ¤– AutomaÃ§Ã£o (Opcional)
Se houver script, pipeline ou aÃ§Ã£o automatizada associada ao runbook, documente aqui.

**Exemplo:**
```bash
# Script: restart-checkout.sh
kubectl rollout restart deployment checkout-service
kubectl rollout status deployment checkout-service
```

**Ferramentas integradas:**
- Ansible Playbook: `playbooks/restart_checkout.yml`
- Jenkins Pipeline: â€œRestart Checkout Deploymentâ€
- Slack ChatOps Command: `/runbook checkout restart`

---

## âœ… ValidaÃ§Ã£o
CritÃ©rios para confirmar que a correÃ§Ã£o funcionou.

| Item | MÃ©trica | CondiÃ§Ã£o esperada | Ferramenta |
|------|----------|------------------|-------------|
| LatÃªncia mÃ©dia | P95 | < 300ms | Grafana |
| Erros 5xx | < 1% | Prometheus | |
| Healthcheck | HTTP 200 | curl /health | |
| Logs | Sem â€œSQLTimeoutExceptionâ€ | Kibana | |

---

## ğŸ“Š EvidÃªncias
Capture dados para auditoria ou aprendizado:
- Captura de logs antes e depois.  
- Screenshots de dashboards.  
- Tempo total de resoluÃ§Ã£o (MTTR).  
- ResponsÃ¡vel pela execuÃ§Ã£o.

**Exemplo:**
```
Data/Hora InÃ­cio: 2025-05-02 14:32
Data/Hora Fim: 2025-05-02 14:39
MTTR: 7 minutos
Executado por: @felipecavalieri
```

---

## ğŸ” Follow-up e Melhorias
Liste aÃ§Ãµes preventivas, automaÃ§Ãµes ou mudanÃ§as futuras:

- Reduzir tamanho do pool de conexÃµes no `application.yaml`.
- Criar alerta para conexÃµes ativas > 90%.
- Automatizar restart via pipeline GitOps.
- Adicionar teste de carga semanal no Grafana k6.

---

## ğŸ§  LiÃ§Ãµes Aprendidas
Preencha apÃ³s o post-mortem:
- O que funcionou bem?  
- O que poderia ser automatizado?  
- Como melhorar a detecÃ§Ã£o precoce?

> â€œRunbooks sÃ£o vivos â€” cada incidente deve aprimorar este documento.â€

---

## ğŸ“š ReferÃªncias e Links
- Dashboard: [Checkout Performance](https://grafana.exemplo.com/d/checkout)
- Logs: [Kibana Checkout Logs](https://kibana.exemplo.com/)
- RepositÃ³rio: [checkout-service GitHub](https://github.com/org/checkout-service)
- Post-Mortem Relacionado: [INC-1045](https://confluence.exemplo.com/incidents/1045)
- SLO: LatÃªncia < 300ms (P95) | Disponibilidade 99.9%

---

## ğŸ‘¥ ResponsÃ¡veis
| Papel | Nome/Grupo | Contato |
|--------|--------------|----------|
| SRE On-Call | Squad Alpha | sre-oncall@empresa.com |
| Dono do ServiÃ§o | Checkout Team | @checkout-team |
| Escalonamento | GerÃªncia SRE | +55 (11) 99999-9999 |

---

## ğŸ“¦ Metadados (para automaÃ§Ã£o)
```yaml
service: checkout-service
severity: P1
created_at: 2025-05-02
last_updated: 2025-11-05
linked_playbook: network-outage-playbook
ai_ready: true
tags:
  - sre
  - runbook
  - database
  - checkout
```

---

## ğŸ’¬ Notas Finais
> Este runbook deve ser revisado a cada **trÃªs meses** ou apÃ³s cada incidente P1 relacionado.  
> VersÃ£o 1.3 â€” Atualizado em **05/11/2025** por **Felipe Cavalieri**.
